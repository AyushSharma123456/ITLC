{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module contains the TrafficSignal class, which represents a traffic signal in the simulation.\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, List, Union\n",
    "\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    raise ImportError(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "class TrafficSignal:\n",
    "    \"\"\"This class represents a Traffic Signal controlling an intersection.\n",
    "\n",
    "    It is responsible for retrieving information and changing the traffic phase using the Traci API.\n",
    "\n",
    "    IMPORTANT: It assumes that the traffic phases defined in the .net file are of the form:\n",
    "        [green_phase, yellow_phase, green_phase, yellow_phase, ...]\n",
    "    Currently it is not supporting all-red phases (but should be easy to implement it).\n",
    "\n",
    "    # Observation Space\n",
    "    The default observation for each traffic signal agent is a vector:\n",
    "\n",
    "    obs = [phase_one_hot, min_green, lane_1_density,...,lane_n_density, lane_1_queue,...,lane_n_queue]\n",
    "\n",
    "    - ```phase_one_hot``` is a one-hot encoded vector indicating the current active green phase\n",
    "    - ```min_green``` is a binary variable indicating whether min_green seconds have already passed in the current phase\n",
    "    - ```lane_i_density``` is the number of vehicles in incoming lane i dividided by the total capacity of the lane\n",
    "    - ```lane_i_queue``` is the number of queued (speed below 0.1 m/s) vehicles in incoming lane i divided by the total capacity of the lane\n",
    "\n",
    "    You can change the observation space by implementing a custom observation class. See :py:class:`sumo_rl.environment.observations.ObservationFunction`.\n",
    "\n",
    "    # Action Space\n",
    "    Action space is discrete, corresponding to which green phase is going to be open for the next delta_time seconds.\n",
    "\n",
    "    # Reward Function\n",
    "    The default reward function is 'diff-waiting-time'. You can change the reward function by implementing a custom reward function and passing to the constructor of :py:class:`sumo_rl.environment.env.SumoEnvironment`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default min gap of SUMO (see https://sumo.dlr.de/docs/Simulation/Safety.html). Should this be parameterized?\n",
    "    MIN_GAP = 2.5\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env,\n",
    "        ts_id: str,\n",
    "        delta_time: int,\n",
    "        yellow_time: int,\n",
    "        min_green: int,\n",
    "        max_green: int,\n",
    "        begin_time: int,\n",
    "        reward_fn: Union[str, Callable],\n",
    "        sumo,\n",
    "    ):\n",
    "        \"\"\"Initializes a TrafficSignal object.\n",
    "\n",
    "        Args:\n",
    "            env (SumoEnvironment): The environment this traffic signal belongs to.\n",
    "            ts_id (str): The id of the traffic signal.\n",
    "            delta_time (int): The time in seconds between actions.\n",
    "            yellow_time (int): The time in seconds of the yellow phase.\n",
    "            min_green (int): The minimum time in seconds of the green phase.\n",
    "            max_green (int): The maximum time in seconds of the green phase.\n",
    "            begin_time (int): The time in seconds when the traffic signal starts operating.\n",
    "            reward_fn (Union[str, Callable]): The reward function. Can be a string with the name of the reward function or a callable function.\n",
    "            sumo (Sumo): The Sumo instance.\n",
    "        \"\"\"\n",
    "        self.id = ts_id\n",
    "        self.env = env\n",
    "        self.delta_time = delta_time\n",
    "        self.yellow_time = yellow_time\n",
    "        self.min_green = min_green\n",
    "        self.max_green = max_green\n",
    "        self.green_phase = 0\n",
    "        self.is_yellow = False\n",
    "        self.time_since_last_phase_change = 0\n",
    "        self.next_action_time = begin_time\n",
    "        self.last_measure = 0.0\n",
    "        self.last_reward = None\n",
    "        self.reward_fn = reward_fn\n",
    "        self.sumo = sumo\n",
    "\n",
    "        if type(self.reward_fn) is str:\n",
    "            if self.reward_fn in TrafficSignal.reward_fns.keys():\n",
    "                self.reward_fn = TrafficSignal.reward_fns[self.reward_fn]\n",
    "            else:\n",
    "                raise NotImplementedError(f\"Reward function {self.reward_fn} not implemented\")\n",
    "\n",
    "        self.observation_fn = self.env.observation_class(self)\n",
    "\n",
    "        self._build_phases()\n",
    "\n",
    "        self.lanes = list(\n",
    "            dict.fromkeys(self.sumo.trafficlight.getControlledLanes(self.id))\n",
    "        )  # Remove duplicates and keep order\n",
    "        self.out_lanes = [link[0][1] for link in self.sumo.trafficlight.getControlledLinks(self.id) if link]\n",
    "        self.out_lanes = list(set(self.out_lanes))\n",
    "        self.lanes_length = {lane: self.sumo.lane.getLength(lane) for lane in self.lanes + self.out_lanes}\n",
    "\n",
    "        self.observation_space = self.observation_fn.observation_space()\n",
    "        self.action_space = spaces.Discrete(self.num_green_phases)\n",
    "\n",
    "    def _build_phases(self):\n",
    "        phases = self.sumo.trafficlight.getAllProgramLogics(self.id)[0].phases\n",
    "        if self.env.fixed_ts:\n",
    "            self.num_green_phases = len(phases) // 2  # Number of green phases == number of phases (green+yellow) divided by 2\n",
    "            return\n",
    "\n",
    "        self.green_phases = []\n",
    "        self.yellow_dict = {}\n",
    "        for phase in phases:\n",
    "            state = phase.state\n",
    "            if \"y\" not in state and (state.count(\"r\") + state.count(\"s\") != len(state)):\n",
    "                self.green_phases.append(self.sumo.trafficlight.Phase(60, state))\n",
    "        self.num_green_phases = len(self.green_phases)\n",
    "        self.all_phases = self.green_phases.copy()\n",
    "\n",
    "        for i, p1 in enumerate(self.green_phases):\n",
    "            for j, p2 in enumerate(self.green_phases):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                yellow_state = \"\"\n",
    "                for s in range(len(p1.state)):\n",
    "                    if (p1.state[s] == \"G\" or p1.state[s] == \"g\") and (p2.state[s] == \"r\" or p2.state[s] == \"s\"):\n",
    "                        yellow_state += \"y\"\n",
    "                    else:\n",
    "                        yellow_state += p1.state[s]\n",
    "                self.yellow_dict[(i, j)] = len(self.all_phases)\n",
    "                self.all_phases.append(self.sumo.trafficlight.Phase(self.yellow_time, yellow_state))\n",
    "\n",
    "        programs = self.sumo.trafficlight.getAllProgramLogics(self.id)\n",
    "        logic = programs[0]\n",
    "        logic.type = 0\n",
    "        logic.phases = self.all_phases\n",
    "        self.sumo.trafficlight.setProgramLogic(self.id, logic)\n",
    "        self.sumo.trafficlight.setRedYellowGreenState(self.id, self.all_phases[0].state)\n",
    "\n",
    "    @property\n",
    "    def time_to_act(self):\n",
    "        \"\"\"Returns True if the traffic signal should act in the current step.\"\"\"\n",
    "        return self.next_action_time == self.env.sim_step\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the traffic signal state.\n",
    "\n",
    "        If the traffic signal should act, it will set the next green phase and update the next action time.\n",
    "        \"\"\"\n",
    "        self.time_since_last_phase_change += 1\n",
    "        if self.is_yellow and self.time_since_last_phase_change == self.yellow_time:\n",
    "            # self.sumo.trafficlight.setPhase(self.id, self.green_phase)\n",
    "            self.sumo.trafficlight.setRedYellowGreenState(self.id, self.all_phases[self.green_phase].state)\n",
    "            self.is_yellow = False\n",
    "\n",
    "    def set_next_phase(self, new_phase: int):\n",
    "        \"\"\"Sets what will be the next green phase and sets yellow phase if the next phase is different than the current.\n",
    "\n",
    "        Args:\n",
    "            new_phase (int): Number between [0 ... num_green_phases]\n",
    "        \"\"\"\n",
    "        new_phase = int(new_phase)\n",
    "        if self.green_phase == new_phase or self.time_since_last_phase_change < self.yellow_time + self.min_green:\n",
    "            # self.sumo.trafficlight.setPhase(self.id, self.green_phase)\n",
    "            self.sumo.trafficlight.setRedYellowGreenState(self.id, self.all_phases[self.green_phase].state)\n",
    "            self.next_action_time = self.env.sim_step + self.delta_time\n",
    "        else:\n",
    "            # self.sumo.trafficlight.setPhase(self.id, self.yellow_dict[(self.green_phase, new_phase)])  # turns yellow\n",
    "            self.sumo.trafficlight.setRedYellowGreenState(\n",
    "                self.id, self.all_phases[self.yellow_dict[(self.green_phase, new_phase)]].state\n",
    "            )\n",
    "            self.green_phase = new_phase\n",
    "            self.next_action_time = self.env.sim_step + self.delta_time\n",
    "            self.is_yellow = True\n",
    "            self.time_since_last_phase_change = 0\n",
    "\n",
    "    def compute_observation(self):\n",
    "        \"\"\"Computes the observation of the traffic signal.\"\"\"\n",
    "        return self.observation_fn()\n",
    "\n",
    "    def compute_reward(self):\n",
    "        \"\"\"Computes the reward of the traffic signal.\"\"\"\n",
    "        self.last_reward = self.reward_fn(self)\n",
    "        return self.last_reward\n",
    "\n",
    "    def _pressure_reward(self):\n",
    "        return self.get_pressure()\n",
    "\n",
    "    def _average_speed_reward(self):\n",
    "        return self.get_average_speed()\n",
    "\n",
    "    def _queue_reward(self):\n",
    "        return -self.get_total_queued()\n",
    "\n",
    "    def _emissions_reward(self):\n",
    "        return -self.get_CO2_emissions()\n",
    "\n",
    "    def _diff_waiting_time_reward(self):\n",
    "        ts_wait = sum(self.get_accumulated_waiting_time_per_lane()) / 100.0\n",
    "        reward = self.last_measure - ts_wait\n",
    "        self.last_measure = ts_wait\n",
    "        return reward\n",
    "\n",
    "    def _observation_fn_default(self):\n",
    "        phase_id = [1 if self.green_phase == i else 0 for i in range(self.num_green_phases)]  # one-hot encoding\n",
    "        min_green = [0 if self.time_since_last_phase_change < self.min_green + self.yellow_time else 1]\n",
    "        density = self.get_lanes_density()\n",
    "        queue = self.get_lanes_queue()\n",
    "        observation = np.array(phase_id + min_green + density + queue, dtype=np.float32)\n",
    "        return observation\n",
    "\n",
    "    def get_accumulated_waiting_time_per_lane(self) -> List[float]:\n",
    "        \"\"\"Returns the accumulated waiting time per lane.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: List of accumulated waiting time of each intersection lane.\n",
    "        \"\"\"\n",
    "        wait_time_per_lane = []\n",
    "        for lane in self.lanes:\n",
    "            veh_list = self.sumo.lane.getLastStepVehicleIDs(lane)\n",
    "            wait_time = 0.0\n",
    "            for veh in veh_list:\n",
    "                veh_lane = self.sumo.vehicle.getLaneID(veh)\n",
    "                acc = self.sumo.vehicle.getAccumulatedWaitingTime(veh)\n",
    "                if veh not in self.env.vehicles:\n",
    "                    self.env.vehicles[veh] = {veh_lane: acc}\n",
    "                else:\n",
    "                    self.env.vehicles[veh][veh_lane] = acc - sum(\n",
    "                        [self.env.vehicles[veh][lane] for lane in self.env.vehicles[veh].keys() if lane != veh_lane]\n",
    "                    )\n",
    "                wait_time += self.env.vehicles[veh][veh_lane]\n",
    "            wait_time_per_lane.append(wait_time)\n",
    "        return wait_time_per_lane\n",
    "\n",
    "    def get_average_speed(self) -> float:\n",
    "        \"\"\"Returns the average speed normalized by the maximum allowed speed of the vehicles in the intersection.\n",
    "\n",
    "        Obs: If there are no vehicles in the intersection, it returns 1.0.\n",
    "        \"\"\"\n",
    "        avg_speed = 0.0\n",
    "        vehs = self._get_veh_list()\n",
    "        if len(vehs) == 0:\n",
    "            return 1.0\n",
    "        for v in vehs:\n",
    "            avg_speed += self.sumo.vehicle.getSpeed(v) / self.sumo.vehicle.getAllowedSpeed(v)\n",
    "        return avg_speed / len(vehs)\n",
    "\n",
    "    def get_CO2_emissions(self):\n",
    "        \n",
    "        \"\"\"Returns the average emissions \n",
    "        \"\"\"\n",
    "        avg_emissions = 0.0\n",
    "        vehs = self._get_veh_list()\n",
    "        if len(vehs) == 0:\n",
    "            return 1.0\n",
    "        for v in vehs:\n",
    "            avg_emissions += self.sumo.vehicle.getCO2Emission(v)\n",
    "        return avg_emissions / len(vehs)\n",
    "\n",
    "    def get_pressure(self):\n",
    "        \"\"\"Returns the pressure (#veh leaving - #veh approaching) of the intersection.\"\"\"\n",
    "        return sum(self.sumo.lane.getLastStepVehicleNumber(lane) for lane in self.out_lanes) - sum(\n",
    "            self.sumo.lane.getLastStepVehicleNumber(lane) for lane in self.lanes\n",
    "        )\n",
    "\n",
    "    def get_out_lanes_density(self) -> List[float]:\n",
    "        \"\"\"Returns the density of the vehicles in the outgoing lanes of the intersection.\"\"\"\n",
    "        lanes_density = [\n",
    "            self.sumo.lane.getLastStepVehicleNumber(lane)\n",
    "            / (self.lanes_length[lane] / (self.MIN_GAP + self.sumo.lane.getLastStepLength(lane)))\n",
    "            for lane in self.out_lanes\n",
    "        ]\n",
    "        return [min(1, density) for density in lanes_density]\n",
    "\n",
    "    def get_lanes_density(self) -> List[float]:\n",
    "        \"\"\"Returns the density [0,1] of the vehicles in the incoming lanes of the intersection.\n",
    "\n",
    "        Obs: The density is computed as the number of vehicles divided by the number of vehicles that could fit in the lane.\n",
    "        \"\"\"\n",
    "        lanes_density = [\n",
    "            self.sumo.lane.getLastStepVehicleNumber(lane)\n",
    "            / (self.lanes_length[lane] / (self.MIN_GAP + self.sumo.lane.getLastStepLength(lane)))\n",
    "            for lane in self.lanes\n",
    "        ]\n",
    "        return [min(1, density) for density in lanes_density]\n",
    "\n",
    "    def get_lanes_queue(self) -> List[float]:\n",
    "        \"\"\"Returns the queue [0,1] of the vehicles in the incoming lanes of the intersection.\n",
    "\n",
    "        Obs: The queue is computed as the number of vehicles halting divided by the number of vehicles that could fit in the lane.\n",
    "        \"\"\"\n",
    "        lanes_queue = [\n",
    "            self.sumo.lane.getLastStepHaltingNumber(lane)\n",
    "            / (self.lanes_length[lane] / (self.MIN_GAP + self.sumo.lane.getLastStepLength(lane)))\n",
    "            for lane in self.lanes\n",
    "        ]\n",
    "        return [min(1, queue) for queue in lanes_queue]\n",
    "\n",
    "    def get_total_queued(self) -> int:\n",
    "        \"\"\"Returns the total number of vehicles halting in the intersection.\"\"\"\n",
    "        return sum(self.sumo.lane.getLastStepHaltingNumber(lane) for lane in self.lanes)\n",
    "\n",
    "    def _get_veh_list(self):\n",
    "        veh_list = []\n",
    "        for lane in self.lanes:\n",
    "            veh_list += self.sumo.lane.getLastStepVehicleIDs(lane)\n",
    "        return veh_list\n",
    "\n",
    "    @classmethod\n",
    "    def register_reward_fn(cls, fn: Callable):\n",
    "        \"\"\"Registers a reward function.\n",
    "\n",
    "        Args:\n",
    "            fn (Callable): The reward function to register.\n",
    "        \"\"\"\n",
    "        if fn.__name__ in cls.reward_fns.keys():\n",
    "            raise KeyError(f\"Reward function {fn.__name__} already exists\")\n",
    "\n",
    "        cls.reward_fns[fn.__name__] = fn\n",
    "\n",
    "    reward_fns = {\n",
    "        \"diff-waiting-time\": _diff_waiting_time_reward,\n",
    "        \"average-speed\": _average_speed_reward,\n",
    "        \"queue\": _queue_reward,\n",
    "        \"pressure\": _pressure_reward,\n",
    "        \"emissions\": _emissions_reward,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5928ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Observation functions for traffic signals.\"\"\"\n",
    "from abc import abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "from .traffic_signal import TrafficSignal\n",
    "\n",
    "\n",
    "class ObservationFunction:\n",
    "    \"\"\"Abstract base class for observation functions.\"\"\"\n",
    "\n",
    "    def __init__(self, ts: TrafficSignal):\n",
    "        \"\"\"Initialize observation function.\"\"\"\n",
    "        self.ts = ts\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self):\n",
    "        \"\"\"Subclasses must override this method.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def observation_space(self):\n",
    "        \"\"\"Subclasses must override this method.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class DefaultObservationFunction(ObservationFunction):\n",
    "    \"\"\"Default observation function for traffic signals.\"\"\"\n",
    "\n",
    "    def __init__(self, ts: TrafficSignal):\n",
    "        \"\"\"Initialize default observation function.\"\"\"\n",
    "        super().__init__(ts)\n",
    "\n",
    "    def __call__(self) -> np.ndarray:\n",
    "        \"\"\"Return the default observation.\"\"\"\n",
    "        phase_id = [1 if self.ts.green_phase == i else 0 for i in range(self.ts.num_green_phases)]  # one-hot encoding\n",
    "        min_green = [0 if self.ts.time_since_last_phase_change < self.ts.min_green + self.ts.yellow_time else 1]\n",
    "        density = self.ts.get_lanes_density()\n",
    "        queue = self.ts.get_lanes_queue()\n",
    "        observation = np.array(phase_id + min_green + density + queue, dtype=np.float32)\n",
    "        return observation\n",
    "\n",
    "    def observation_space(self) -> spaces.Box:\n",
    "        \"\"\"Return the observation space.\"\"\"\n",
    "        return spaces.Box(\n",
    "            low=np.zeros(self.ts.num_green_phases + 1 + 2 * len(self.ts.lanes), dtype=np.float32),\n",
    "            high=np.ones(self.ts.num_green_phases + 1 + 2 * len(self.ts.lanes), dtype=np.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac7cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SUMO Environment for Traffic Signal Control.\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Tuple, Union\n",
    "\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    raise ImportError(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sumolib\n",
    "import traci\n",
    "from gymnasium.utils import EzPickle, seeding\n",
    "from pettingzoo import AECEnv\n",
    "from pettingzoo.utils import agent_selector, wrappers\n",
    "from pettingzoo.utils.conversions import parallel_wrapper_fn\n",
    "\n",
    "from .observations import DefaultObservationFunction, ObservationFunction\n",
    "from .traffic_signal import TrafficSignal\n",
    "\n",
    "\n",
    "LIBSUMO = \"LIBSUMO_AS_TRACI\" in os.environ\n",
    "\n",
    "\n",
    "def env(**kwargs):\n",
    "    \"\"\"Instantiate a PettingoZoo environment.\"\"\"\n",
    "    env = SumoEnvironmentPZ(**kwargs)\n",
    "    env = wrappers.AssertOutOfBoundsWrapper(env)\n",
    "    env = wrappers.OrderEnforcingWrapper(env)\n",
    "    return env\n",
    "\n",
    "\n",
    "parallel_env = parallel_wrapper_fn(env)\n",
    "\n",
    "\n",
    "class SumoEnvironment(gym.Env):\n",
    "    \"\"\"SUMO Environment for Traffic Signal Control.\n",
    "\n",
    "    Class that implements a gym.Env interface for traffic signal control using the SUMO simulator.\n",
    "    See https://sumo.dlr.de/docs/ for details on SUMO.\n",
    "    See https://gymnasium.farama.org/ for details on gymnasium.\n",
    "\n",
    "    Args:\n",
    "        net_file (str): SUMO .net.xml file\n",
    "        route_file (str): SUMO .rou.xml file\n",
    "        out_csv_name (Optional[str]): name of the .csv output with simulation results. If None, no output is generated\n",
    "        use_gui (bool): Whether to run SUMO simulation with the SUMO GUI\n",
    "        virtual_display (Optional[Tuple[int,int]]): Resolution of the virtual display for rendering\n",
    "        begin_time (int): The time step (in seconds) the simulation starts. Default: 0\n",
    "        num_seconds (int): Number of simulated seconds on SUMO. The duration in seconds of the simulation. Default: 20000\n",
    "        max_depart_delay (int): Vehicles are discarded if they could not be inserted after max_depart_delay seconds. Default: -1 (no delay)\n",
    "        waiting_time_memory (int): Number of seconds to remember the waiting time of a vehicle (see https://sumo.dlr.de/pydoc/traci._vehicle.html#VehicleDomain-getAccumulatedWaitingTime). Default: 1000\n",
    "        time_to_teleport (int): Time in seconds to teleport a vehicle to the end of the edge if it is stuck. Default: -1 (no teleport)\n",
    "        delta_time (int): Simulation seconds between actions. Default: 5 seconds\n",
    "        yellow_time (int): Duration of the yellow phase. Default: 2 seconds\n",
    "        min_green (int): Minimum green time in a phase. Default: 5 seconds\n",
    "        max_green (int): Max green time in a phase. Default: 60 seconds. Warning: This parameter is currently ignored!\n",
    "        single_agent (bool): If true, it behaves like a regular gym.Env. Else, it behaves like a MultiagentEnv (returns dict of observations, rewards, dones, infos).\n",
    "        reward_fn (str/function/dict): String with the name of the reward function used by the agents, a reward function, or dictionary with reward functions assigned to individual traffic lights by their keys.\n",
    "        observation_class (ObservationFunction): Inherited class which has both the observation function and observation space.\n",
    "        add_system_info (bool): If true, it computes system metrics (total queue, total waiting time, average speed) in the info dictionary.\n",
    "        add_per_agent_info (bool): If true, it computes per-agent (per-traffic signal) metrics (average accumulated waiting time, average queue) in the info dictionary.\n",
    "        sumo_seed (int/string): Random seed for sumo. If 'random' it uses a randomly chosen seed.\n",
    "        fixed_ts (bool): If true, it will follow the phase configuration in the route_file and ignore the actions given in the :meth:`step` method.\n",
    "        sumo_warnings (bool): If true, it will print SUMO warnings.\n",
    "        additional_sumo_cmd (str): Additional SUMO command line arguments.\n",
    "        render_mode (str): Mode of rendering. Can be 'human' or 'rgb_array'. Default: None\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "    }\n",
    "\n",
    "    CONNECTION_LABEL = 0  # For traci multi-client support\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net_file: str,\n",
    "        route_file: str,\n",
    "        out_csv_name: Optional[str] = None,\n",
    "        use_gui: bool = False,\n",
    "        virtual_display: Tuple[int, int] = (3200, 1800),\n",
    "        begin_time: int = 0,\n",
    "        num_seconds: int = 20000,\n",
    "        max_depart_delay: int = -1,\n",
    "        waiting_time_memory: int = 1000,\n",
    "        time_to_teleport: int = -1,\n",
    "        delta_time: int = 5,\n",
    "        yellow_time: int = 2,\n",
    "        min_green: int = 5,\n",
    "        max_green: int = 50,\n",
    "        single_agent: bool = False,\n",
    "        reward_fn: Union[str, Callable, dict] = \"emissions\",\n",
    "        observation_class: ObservationFunction = DefaultObservationFunction,\n",
    "        add_system_info: bool = False,\n",
    "        add_per_agent_info: bool = False,\n",
    "        sumo_seed: Union[str, int] = \"random\",\n",
    "        fixed_ts: bool = False,\n",
    "        sumo_warnings: bool = True,\n",
    "        additional_sumo_cmd: Optional[str] = None,\n",
    "        render_mode: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the environment.\"\"\"\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"], \"Invalid render mode.\"\n",
    "        self.render_mode = render_mode\n",
    "        self.virtual_display = virtual_display\n",
    "        self.disp = None\n",
    "\n",
    "        self._net = net_file\n",
    "        self._route = route_file\n",
    "        self.use_gui = use_gui\n",
    "        if self.use_gui or self.render_mode is not None:\n",
    "            self._sumo_binary = sumolib.checkBinary(\"sumo-gui\")\n",
    "        else:\n",
    "            self._sumo_binary = sumolib.checkBinary(\"sumo\")\n",
    "\n",
    "        assert delta_time > yellow_time, \"Time between actions must be at least greater than yellow time.\"\n",
    "\n",
    "        self.begin_time = begin_time\n",
    "        self.sim_max_time = begin_time + num_seconds\n",
    "        self.delta_time = delta_time  # seconds on sumo at each step\n",
    "        self.max_depart_delay = max_depart_delay  # Max wait time to insert a vehicle\n",
    "        self.waiting_time_memory = waiting_time_memory  # Number of seconds to remember the waiting time of a vehicle (see https://sumo.dlr.de/pydoc/traci._vehicle.html#VehicleDomain-getAccumulatedWaitingTime)\n",
    "        self.time_to_teleport = time_to_teleport\n",
    "        self.min_green = min_green\n",
    "        self.max_green = max_green\n",
    "        self.yellow_time = yellow_time\n",
    "        self.single_agent = single_agent\n",
    "        self.reward_fn = reward_fn\n",
    "        self.sumo_seed = sumo_seed\n",
    "        self.fixed_ts = fixed_ts\n",
    "        self.sumo_warnings = sumo_warnings\n",
    "        self.additional_sumo_cmd = additional_sumo_cmd\n",
    "        self.add_system_info = add_system_info\n",
    "        self.add_per_agent_info = add_per_agent_info\n",
    "        self.label = str(SumoEnvironment.CONNECTION_LABEL)\n",
    "        SumoEnvironment.CONNECTION_LABEL += 1\n",
    "        self.sumo = None\n",
    "\n",
    "        if LIBSUMO:\n",
    "            traci.start([sumolib.checkBinary(\"sumo\"), \"-n\", self._net])  # Start only to retrieve traffic light information\n",
    "            conn = traci\n",
    "        else:\n",
    "            traci.start([sumolib.checkBinary(\"sumo\"), \"-n\", self._net], label=\"init_connection\" + self.label)\n",
    "            conn = traci.getConnection(\"init_connection\" + self.label)\n",
    "\n",
    "        self.ts_ids = list(conn.trafficlight.getIDList())\n",
    "        self.observation_class = observation_class\n",
    "\n",
    "        if isinstance(self.reward_fn, dict):\n",
    "            self.traffic_signals = {\n",
    "                ts: TrafficSignal(\n",
    "                    self,\n",
    "                    ts,\n",
    "                    self.delta_time,\n",
    "                    self.yellow_time,\n",
    "                    self.min_green,\n",
    "                    self.max_green,\n",
    "                    self.begin_time,\n",
    "                    self.reward_fn[ts],\n",
    "                    conn,\n",
    "                )\n",
    "                for ts in self.reward_fn.keys()\n",
    "            }\n",
    "        else:\n",
    "            self.traffic_signals = {\n",
    "                ts: TrafficSignal(\n",
    "                    self,\n",
    "                    ts,\n",
    "                    self.delta_time,\n",
    "                    self.yellow_time,\n",
    "                    self.min_green,\n",
    "                    self.max_green,\n",
    "                    self.begin_time,\n",
    "                    self.reward_fn,\n",
    "                    conn,\n",
    "                )\n",
    "                for ts in self.ts_ids\n",
    "            }\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "        self.vehicles = dict()\n",
    "        self.reward_range = (-float(\"inf\"), float(\"inf\"))\n",
    "        self.episode = 0\n",
    "        self.metrics = []\n",
    "        self.out_csv_name = out_csv_name\n",
    "        self.observations = {ts: None for ts in self.ts_ids}\n",
    "        self.rewards = {ts: None for ts in self.ts_ids}\n",
    "\n",
    "    def _start_simulation(self):\n",
    "        sumo_cmd = [\n",
    "            self._sumo_binary,\n",
    "            \"-n\",\n",
    "            self._net,\n",
    "            \"-r\",\n",
    "            self._route,\n",
    "            \"--max-depart-delay\",\n",
    "            str(self.max_depart_delay),\n",
    "            \"--waiting-time-memory\",\n",
    "            str(self.waiting_time_memory),\n",
    "            \"--time-to-teleport\",\n",
    "            str(self.time_to_teleport),\n",
    "        ]\n",
    "        if self.begin_time > 0:\n",
    "            sumo_cmd.append(f\"-b {self.begin_time}\")\n",
    "        if self.sumo_seed == \"random\":\n",
    "            sumo_cmd.append(\"--random\")\n",
    "        else:\n",
    "            sumo_cmd.extend([\"--seed\", str(self.sumo_seed)])\n",
    "        if not self.sumo_warnings:\n",
    "            sumo_cmd.append(\"--no-warnings\")\n",
    "        if self.additional_sumo_cmd is not None:\n",
    "            sumo_cmd.extend(self.additional_sumo_cmd.split())\n",
    "        if self.use_gui or self.render_mode is not None:\n",
    "            sumo_cmd.extend([\"--start\", \"--quit-on-end\"])\n",
    "            if self.render_mode == \"rgb_array\":\n",
    "                sumo_cmd.extend([\"--window-size\", f\"{self.virtual_display[0]},{self.virtual_display[1]}\"])\n",
    "                from pyvirtualdisplay.smartdisplay import SmartDisplay\n",
    "\n",
    "                print(\"Creating a virtual display.\")\n",
    "                self.disp = SmartDisplay(size=self.virtual_display)\n",
    "                self.disp.start()\n",
    "                print(\"Virtual display started.\")\n",
    "\n",
    "        if LIBSUMO:\n",
    "            traci.start(sumo_cmd)\n",
    "            self.sumo = traci\n",
    "        else:\n",
    "            traci.start(sumo_cmd, label=self.label)\n",
    "            self.sumo = traci.getConnection(self.label)\n",
    "\n",
    "        if self.use_gui or self.render_mode is not None:\n",
    "            self.sumo.gui.setSchema(traci.gui.DEFAULT_VIEW, \"real world\")\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, **kwargs):\n",
    "        \"\"\"Reset the environment.\"\"\"\n",
    "        super().reset(seed=seed, **kwargs)\n",
    "\n",
    "        if self.episode != 0:\n",
    "            self.close()\n",
    "            self.save_csv(self.out_csv_name, self.episode)\n",
    "        self.episode += 1\n",
    "        self.metrics = []\n",
    "\n",
    "        if seed is not None:\n",
    "            self.sumo_seed = seed\n",
    "        self._start_simulation()\n",
    "\n",
    "        if isinstance(self.reward_fn, dict):\n",
    "            self.traffic_signals = {\n",
    "                ts: TrafficSignal(\n",
    "                    self,\n",
    "                    ts,\n",
    "                    self.delta_time,\n",
    "                    self.yellow_time,\n",
    "                    self.min_green,\n",
    "                    self.max_green,\n",
    "                    self.begin_time,\n",
    "                    self.reward_fn[ts],\n",
    "                    self.sumo,\n",
    "                )\n",
    "                for ts in self.reward_fn.keys()\n",
    "            }\n",
    "        else:\n",
    "            self.traffic_signals = {\n",
    "                ts: TrafficSignal(\n",
    "                    self,\n",
    "                    ts,\n",
    "                    self.delta_time,\n",
    "                    self.yellow_time,\n",
    "                    self.min_green,\n",
    "                    self.max_green,\n",
    "                    self.begin_time,\n",
    "                    self.reward_fn,\n",
    "                    self.sumo,\n",
    "                )\n",
    "                for ts in self.ts_ids\n",
    "            }\n",
    "\n",
    "        self.vehicles = dict()\n",
    "\n",
    "        if self.single_agent:\n",
    "            return self._compute_observations()[self.ts_ids[0]], self._compute_info()\n",
    "        else:\n",
    "            return self._compute_observations()\n",
    "\n",
    "    @property\n",
    "    def sim_step(self) -> float:\n",
    "        \"\"\"Return current simulation second on SUMO.\"\"\"\n",
    "        return self.sumo.simulation.getTime()\n",
    "\n",
    "    def step(self, action: Union[dict, int]):\n",
    "        \"\"\"Apply the action(s) and then step the simulation for delta_time seconds.\n",
    "\n",
    "        Args:\n",
    "            action (Union[dict, int]): action(s) to be applied to the environment.\n",
    "            If single_agent is True, action is an int, otherwise it expects a dict with keys corresponding to traffic signal ids.\n",
    "        \"\"\"\n",
    "        # No action, follow fixed TL defined in self.phases\n",
    "        if action is None or action == {}:\n",
    "            for _ in range(self.delta_time):\n",
    "                self._sumo_step()\n",
    "        else:\n",
    "            self._apply_actions(action)\n",
    "            self._run_steps()\n",
    "\n",
    "        observations = self._compute_observations()\n",
    "        rewards = self._compute_rewards()\n",
    "        dones = self._compute_dones()\n",
    "        terminated = False  # there are no 'terminal' states in this environment\n",
    "        truncated = dones[\"__all__\"]  # episode ends when sim_step >= max_steps\n",
    "        info = self._compute_info()\n",
    "\n",
    "        if self.single_agent:\n",
    "            return observations[self.ts_ids[0]], rewards[self.ts_ids[0]], terminated, truncated, info\n",
    "        else:\n",
    "            return observations, rewards, dones, info\n",
    "\n",
    "    def _run_steps(self):\n",
    "        time_to_act = False\n",
    "        while not time_to_act:\n",
    "            self._sumo_step()\n",
    "            for ts in self.ts_ids:\n",
    "                self.traffic_signals[ts].update()\n",
    "                if self.traffic_signals[ts].time_to_act:\n",
    "                    time_to_act = True\n",
    "\n",
    "    def _apply_actions(self, actions):\n",
    "        \"\"\"Set the next green phase for the traffic signals.\n",
    "\n",
    "        Args:\n",
    "            actions: If single-agent, actions is an int between 0 and self.num_green_phases (next green phase)\n",
    "                     If multiagent, actions is a dict {ts_id : greenPhase}\n",
    "        \"\"\"\n",
    "        if self.single_agent:\n",
    "            if self.traffic_signals[self.ts_ids[0]].time_to_act:\n",
    "                self.traffic_signals[self.ts_ids[0]].set_next_phase(actions)\n",
    "        else:\n",
    "            for ts, action in actions.items():\n",
    "                if self.traffic_signals[ts].time_to_act:\n",
    "                    self.traffic_signals[ts].set_next_phase(action)\n",
    "\n",
    "    def _compute_dones(self):\n",
    "        dones = {ts_id: False for ts_id in self.ts_ids}\n",
    "        dones[\"__all__\"] = self.sim_step >= self.sim_max_time\n",
    "        return dones\n",
    "\n",
    "    def _compute_info(self):\n",
    "        info = {\"step\": self.sim_step}\n",
    "        if self.add_system_info:\n",
    "            info.update(self._get_system_info())\n",
    "        if self.add_per_agent_info:\n",
    "            info.update(self._get_per_agent_info())\n",
    "        self.metrics.append(info.copy())\n",
    "        return info\n",
    "\n",
    "    def _compute_observations(self):\n",
    "        self.observations.update(\n",
    "            {ts: self.traffic_signals[ts].compute_observation() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act}\n",
    "        )\n",
    "        return {ts: self.observations[ts].copy() for ts in self.observations.keys() if self.traffic_signals[ts].time_to_act}\n",
    "\n",
    "    def _compute_rewards(self):\n",
    "        self.rewards.update(\n",
    "            {ts: self.traffic_signals[ts].compute_reward() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act}\n",
    "        )\n",
    "        return {ts: self.rewards[ts] for ts in self.rewards.keys() if self.traffic_signals[ts].time_to_act}\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        \"\"\"Return the observation space of a traffic signal.\n",
    "\n",
    "        Only used in case of single-agent environment.\n",
    "        \"\"\"\n",
    "        return self.traffic_signals[self.ts_ids[0]].observation_space\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        \"\"\"Return the action space of a traffic signal.\n",
    "\n",
    "        Only used in case of single-agent environment.\n",
    "        \"\"\"\n",
    "        return self.traffic_signals[self.ts_ids[0]].action_space\n",
    "\n",
    "    def observation_spaces(self, ts_id: str):\n",
    "        \"\"\"Return the observation space of a traffic signal.\"\"\"\n",
    "        return self.traffic_signals[ts_id].observation_space\n",
    "\n",
    "    def action_spaces(self, ts_id: str) -> gym.spaces.Discrete:\n",
    "        \"\"\"Return the action space of a traffic signal.\"\"\"\n",
    "        return self.traffic_signals[ts_id].action_space\n",
    "\n",
    "    def _sumo_step(self):\n",
    "        self.sumo.simulationStep()\n",
    "\n",
    "    def _get_system_info(self):\n",
    "        vehicles = self.sumo.vehicle.getIDList()\n",
    "        speeds = [self.sumo.vehicle.getSpeed(vehicle) for vehicle in vehicles]\n",
    "        waiting_times = [self.sumo.vehicle.getWaitingTime(vehicle) for vehicle in vehicles]\n",
    "        emission_info=[self.sumo.vehicle.getCO2Emission(vehicle) for vehicle in vehicles]\n",
    "        return {\n",
    "            # In SUMO, a vehicle is considered halting if its speed is below 0.1 m/s\n",
    "            \"system_total_stopped\": sum(int(speed < 0.1) for speed in speeds),\n",
    "            \"system_total_waiting_time\": sum(waiting_times),\n",
    "            \"system_mean_waiting_time\": 0.0 if len(vehicles) == 0 else np.mean(waiting_times),\n",
    "            \"system_mean_speed\": 0.0 if len(vehicles) == 0 else np.mean(speeds),\n",
    "            \"system_total_emissions\": sum(emission_info),\n",
    "            \"system_mean_emissions\": 0.0 if len(vehicles) == 0 else np.mean(emission_info)\n",
    "        }\n",
    "\n",
    "    def _get_per_agent_info(self):\n",
    "        stopped = [self.traffic_signals[ts].get_total_queued() for ts in self.ts_ids]\n",
    "        accumulated_waiting_time = [\n",
    "            sum(self.traffic_signals[ts].get_accumulated_waiting_time_per_lane()) for ts in self.ts_ids\n",
    "        ]\n",
    "        average_speed = [self.traffic_signals[ts].get_average_speed() for ts in self.ts_ids]\n",
    "        info = {}\n",
    "        for i, ts in enumerate(self.ts_ids):\n",
    "            info[f\"{ts}_stopped\"] = stopped[i]\n",
    "            info[f\"{ts}_accumulated_waiting_time\"] = accumulated_waiting_time[i]\n",
    "            info[f\"{ts}_average_speed\"] = average_speed[i]\n",
    "        info[\"agents_total_stopped\"] = sum(stopped)\n",
    "        info[\"agents_total_accumulated_waiting_time\"] = sum(accumulated_waiting_time)\n",
    "        return info\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the environment and stop the SUMO simulation.\"\"\"\n",
    "        if self.sumo is None:\n",
    "            return\n",
    "\n",
    "        if not LIBSUMO:\n",
    "            traci.switch(self.label)\n",
    "        traci.close()\n",
    "\n",
    "        if self.disp is not None:\n",
    "            self.disp.stop()\n",
    "            self.disp = None\n",
    "\n",
    "        self.sumo = None\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Close the environment and stop the SUMO simulation.\"\"\"\n",
    "        self.close()\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render the environment.\n",
    "\n",
    "        If render_mode is \"human\", the environment will be rendered in a GUI window using pyvirtualdisplay.\n",
    "        \"\"\"\n",
    "        if self.render_mode == \"human\":\n",
    "            return  # sumo-gui will already be rendering the frame\n",
    "        elif self.render_mode == \"rgb_array\":\n",
    "            # img = self.sumo.gui.screenshot(traci.gui.DEFAULT_VIEW,\n",
    "            #                          f\"temp/img{self.sim_step}.jpg\",\n",
    "            #                          width=self.virtual_display[0],\n",
    "            #                          height=self.virtual_display[1])\n",
    "            img = self.disp.grab()\n",
    "            return np.array(img)\n",
    "\n",
    "    def save_csv(self, out_csv_name, episode):\n",
    "        \"\"\"Save metrics of the simulation to a .csv file.\n",
    "\n",
    "        Args:\n",
    "            out_csv_name (str): Path to the output .csv file. E.g.: \"results/my_results\n",
    "            episode (int): Episode number to be appended to the output file name.\n",
    "        \"\"\"\n",
    "        if out_csv_name is not None:\n",
    "            df = pd.DataFrame(self.metrics)\n",
    "            Path(Path(out_csv_name).parent).mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(out_csv_name + f\"_conn{self.label}_ep{episode}\" + \".csv\", index=False)\n",
    "\n",
    "    # Below functions are for discrete state space\n",
    "\n",
    "    def encode(self, state, ts_id):\n",
    "        \"\"\"Encode the state of the traffic signal into a hashable object.\"\"\"\n",
    "        phase = int(np.where(state[: self.traffic_signals[ts_id].num_green_phases] == 1)[0])\n",
    "        min_green = state[self.traffic_signals[ts_id].num_green_phases]\n",
    "        density_queue = [self._discretize_density(d) for d in state[self.traffic_signals[ts_id].num_green_phases + 1 :]]\n",
    "        # tuples are hashable and can be used as key in python dictionary\n",
    "        return tuple([phase, min_green] + density_queue)\n",
    "\n",
    "    def _discretize_density(self, density):\n",
    "        return min(int(density * 10), 9)\n",
    "\n",
    "\n",
    "class SumoEnvironmentPZ(AECEnv, EzPickle):\n",
    "    \"\"\"A wrapper for the SUMO environment that implements the AECEnv interface from PettingZoo.\n",
    "\n",
    "    For more information, see https://pettingzoo.farama.org/api/aec/.\n",
    "\n",
    "    The arguments are the same as for :py:class:`sumo_rl.environment.env.SumoEnvironment`.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"name\": \"sumo_rl_v0\", \"is_parallelizable\": True}\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize the environment.\"\"\"\n",
    "        EzPickle.__init__(self, **kwargs)\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "        self.seed()\n",
    "        self.env = SumoEnvironment(**self._kwargs)\n",
    "\n",
    "        self.agents = self.env.ts_ids\n",
    "        self.possible_agents = self.env.ts_ids\n",
    "        self._agent_selector = agent_selector(self.agents)\n",
    "        self.agent_selection = self._agent_selector.reset()\n",
    "        # spaces\n",
    "        self.action_spaces = {a: self.env.action_spaces(a) for a in self.agents}\n",
    "        self.observation_spaces = {a: self.env.observation_spaces(a) for a in self.agents}\n",
    "\n",
    "        # dicts\n",
    "        self.rewards = {a: 0 for a in self.agents}\n",
    "        self.terminations = {a: False for a in self.agents}\n",
    "        self.truncations = {a: False for a in self.agents}\n",
    "        self.infos = {a: {} for a in self.agents}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        \"\"\"Set the seed for the environment.\"\"\"\n",
    "        self.randomizer, seed = seeding.np_random(seed)\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        \"\"\"Reset the environment.\"\"\"\n",
    "        self.env.reset(seed=seed, options=options)\n",
    "        self.agents = self.possible_agents[:]\n",
    "        self.agent_selection = self._agent_selector.reset()\n",
    "        self.rewards = {agent: 0 for agent in self.agents}\n",
    "        self._cumulative_rewards = {agent: 0 for agent in self.agents}\n",
    "        self.terminations = {a: False for a in self.agents}\n",
    "        self.truncations = {a: False for a in self.agents}\n",
    "        self.compute_info()\n",
    "\n",
    "    def compute_info(self):\n",
    "        \"\"\"Compute the info for the current step.\"\"\"\n",
    "        self.infos = {a: {} for a in self.agents}\n",
    "        infos = self.env._compute_info()\n",
    "        for a in self.agents:\n",
    "            for k, v in infos.items():\n",
    "                if k.startswith(a) or k.startswith(\"system\"):\n",
    "                    self.infos[a][k] = v\n",
    "\n",
    "    def observation_space(self, agent):\n",
    "        \"\"\"Return the observation space for the agent.\"\"\"\n",
    "        return self.observation_spaces[agent]\n",
    "\n",
    "    def action_space(self, agent):\n",
    "        \"\"\"Return the action space for the agent.\"\"\"\n",
    "        return self.action_spaces[agent]\n",
    "\n",
    "    def observe(self, agent):\n",
    "        \"\"\"Return the observation for the agent.\"\"\"\n",
    "        obs = self.env.observations[agent].copy()\n",
    "        return obs\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the environment and stop the SUMO simulation.\"\"\"\n",
    "        self.env.close()\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render the environment.\"\"\"\n",
    "        return self.env.render()\n",
    "\n",
    "    def save_csv(self, out_csv_name, episode):\n",
    "        \"\"\"Save metrics of the simulation to a .csv file.\"\"\"\n",
    "        self.env.save_csv(out_csv_name, episode)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Step the environment.\"\"\"\n",
    "        if self.truncations[self.agent_selection] or self.terminations[self.agent_selection]:\n",
    "            return self._was_dead_step(action)\n",
    "        agent = self.agent_selection\n",
    "        if not self.action_spaces[agent].contains(action):\n",
    "            raise Exception(\n",
    "                \"Action for agent {} must be in Discrete({}).\"\n",
    "                \"It is currently {}\".format(agent, self.action_spaces[agent].n, action)\n",
    "            )\n",
    "\n",
    "        self.env._apply_actions({agent: action})\n",
    "\n",
    "        if self._agent_selector.is_last():\n",
    "            self.env._run_steps()\n",
    "            self.env._compute_observations()\n",
    "            self.rewards = self.env._compute_rewards()\n",
    "            self.compute_info()\n",
    "        else:\n",
    "            self._clear_rewards()\n",
    "\n",
    "        done = self.env._compute_dones()[\"__all__\"]\n",
    "        self.truncations = {a: done for a in self.agents}\n",
    "\n",
    "        self.agent_selection = self._agent_selector.next()\n",
    "        self._cumulative_rewards[agent] = 0\n",
    "        self._accumulate_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "\n",
    "from sumo_rl import SumoEnvironment\n",
    "from sumo_rl.agents import QLAgent\n",
    "from sumo_rl.exploration import EpsilonGreedy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alpha = 0.1\n",
    "    gamma = 0.99\n",
    "    decay = 1\n",
    "    runs = 1\n",
    "    episodes = 1\n",
    "\n",
    "    env = SumoEnvironment(\n",
    "        net_file=\"nets/4x4-Lucas/4x4.net.xml\",\n",
    "        route_file=\"nets/4x4-Lucas/4x4c1c2c1c2.rou.xml\",\n",
    "        use_gui=False,\n",
    "        num_seconds=100,\n",
    "        min_green=5,\n",
    "        delta_time=5,\n",
    "        add_system_info = True,\n",
    "        add_per_agent_info = False,\n",
    "    )\n",
    "\n",
    "    for run in range(1, runs + 1):\n",
    "        initial_states = env.reset()\n",
    "        ql_agents = {\n",
    "            ts: QLAgent(\n",
    "                starting_state=env.encode(initial_states[ts], ts),\n",
    "                state_space=env.observation_space,\n",
    "                action_space=env.action_space,\n",
    "                alpha=alpha,\n",
    "                gamma=gamma,\n",
    "                exploration_strategy=EpsilonGreedy(initial_epsilon=0.05, min_epsilon=0.005, decay=decay),\n",
    "            )\n",
    "            for ts in env.ts_ids\n",
    "        }\n",
    "\n",
    "        for episode in range(1, episodes + 1):\n",
    "            if episode != 1:\n",
    "                initial_states = env.reset()\n",
    "                for ts in initial_states.keys():\n",
    "                    ql_agents[ts].state = env.encode(initial_states[ts], ts)\n",
    "\n",
    "            infos = []\n",
    "            done = {\"__all__\": False}\n",
    "            while not done[\"__all__\"]:\n",
    "                actions = {ts: ql_agents[ts].act() for ts in ql_agents.keys()}\n",
    "\n",
    "                s, r, done, info = env.step(action=actions)\n",
    "\n",
    "                for agent_id in s.keys():\n",
    "                    ql_agents[agent_id].learn(next_state=env.encode(s[agent_id], agent_id), reward=r[agent_id])\n",
    "\n",
    "            env.save_csv(f\"outputs/4x4/ql-4x4grid_run{run}\", episode)\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
